{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_1024 = pd.read_csv('Election2020/1024e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_1025 = pd.read_csv('Election2020/1025e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1026 = pd.read_csv('Election2020/1026e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1027 = pd.read_csv('Election2020/1027e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1028 = pd.read_csv('Election2020/1028e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1029 = pd.read_csv('Election2020/1029e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1030 = pd.read_csv('Election2020/1030e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1031 = pd.read_csv('Election2020/1031e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1101 = pd.read_csv('Election2020/1101e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1102 = pd.read_csv('Election2020/1102e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1103 = pd.read_csv('Election2020/1103e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1104 = pd.read_csv('Election2020/1104e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1105 = pd.read_csv('Election2020/1105e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1106 = pd.read_csv('Election2020/1106e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1107 = pd.read_csv('Election2020/1107e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1108 = pd.read_csv('Election2020/1108e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1109 = pd.read_csv('Election2020/1109e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1110 = pd.read_csv('Election2020/1110e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1111 = pd.read_csv('Election2020/1111e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1112 = pd.read_csv('Election2020/1112e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_1113 = pd.read_csv('Election2020/1113e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "e_0106 =  pd.read_csv('Election2020/0106e.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "election2020_tweets = pd.concat([e_1024, e_1025, e_1026,e_1027,e_1028,e_1029,e_1030,e_1031,e_1101,e_1102,e_1103,e_1104,e_1105,e_1106,e_1107,e_1108,e_1109, e_1110,e_1111,e_1112, e_1113,e_0106], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21639"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(election2020_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17403"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#screen out all the English tweets\n",
    "election2020_tweets = election2020_tweets[election2020_tweets['language']=='en']\n",
    "election2020_tweets.reset_index(inplace = True)\n",
    "len(election2020_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove URL from tweets\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r'http\\S+', '', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "election2020_tweets['tweet'] = election2020_tweets['tweet'].map(lambda x: remove_URL(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercases\n",
    "election2020_tweets['tweet'] = election2020_tweets['tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all non-alphabetical character with whitespaces\n",
    "election2020_tweets['tweet'] = election2020_tweets['tweet'].str.replace(r'[^a-zA-Z]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable = ['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize\n",
    "election2020_tweets['docs'] = election2020_tweets['tweet'].map(lambda y: nlp(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "election2020_tweets['lemmatization'] = election2020_tweets['docs'].map(lambda z: \" \".join([word.lemma_ for word in z ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "election2020_tweets['s_token'] = election2020_tweets['lemmatization'].map(lambda a:word_tokenize(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'rule', 'if', 'you', 'vote', 'election']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "election2020_tweets['s_token'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "election2020_tweets.to_csv('election2020_cleaned_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'election2020_tweets' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store election2020_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
