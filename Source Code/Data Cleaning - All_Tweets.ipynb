{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trump_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r biden_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r election2020_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = pd.concat([trump_tweets, biden_tweets, election2020_tweets], ignore_index = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    51915\n",
       "True      5154\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check how many tweets are duplicated\n",
    "all_tweets.duplicated(subset = ['tweet']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The total number of collected tweets is 51915+5154 = 57069**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qm/j2nyw_6j7272_3cq86kpw75r0000gn/T/ipykernel_961/1800528475.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop_duplicates except for the argument 'subset' will be keyword-only\n",
      "  all_tweets.drop_duplicates('tweet','first', inplace = True)\n"
     ]
    }
   ],
   "source": [
    "#delete identical tweets\n",
    "all_tweets.drop_duplicates('tweet','first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51915"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords from 's_token' column\n",
    "stops = set(stopwords.words(\"english\")) #stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveStopwords(x):\n",
    "    a = []\n",
    "    for word in x:\n",
    "        if word not in stops:\n",
    "            a.append(word)\n",
    "            \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_tweets['token'] = all_tweets['s_token'].map(lambda x: RemoveStopwords(x))\n",
    "#w for w in corpus if not w in stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>tweet</th>\n",
       "      <th>language</th>\n",
       "      <th>user_id_str</th>\n",
       "      <th>username</th>\n",
       "      <th>docs</th>\n",
       "      <th>lemmatization</th>\n",
       "      <th>s_token</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-10-24 00:59:59</td>\n",
       "      <td>chikooslim i was thinking that since it was t...</td>\n",
       "      <td>en</td>\n",
       "      <td>18491914</td>\n",
       "      <td>slattfri</td>\n",
       "      <td>( , chikooslim, i, was, thinking, that, since,...</td>\n",
       "      <td>chikooslim I be think that since it be the d...</td>\n",
       "      <td>[chikooslim, I, be, think, that, since, it, be...</td>\n",
       "      <td>[chikooslim, I, think, since, daughter, refuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-10-24 00:59:59</td>\n",
       "      <td>he s been saying that for four years   alllies...</td>\n",
       "      <td>en</td>\n",
       "      <td>46384399</td>\n",
       "      <td>francesmiddlet2</td>\n",
       "      <td>(he, s, been, saying, that, for, four, years, ...</td>\n",
       "      <td>he s be say that for four year    alllie   tru...</td>\n",
       "      <td>[he, s, be, say, that, for, four, year, alllie...</td>\n",
       "      <td>[say, four, year, alllie, trumplie, time, narc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-10-24 00:59:59</td>\n",
       "      <td>incredibly thought provoking article  make sur...</td>\n",
       "      <td>en</td>\n",
       "      <td>2902130034</td>\n",
       "      <td>mfly1971</td>\n",
       "      <td>(incredibly, thought, provoking, article,  , m...</td>\n",
       "      <td>incredibly think provoke article   make sure y...</td>\n",
       "      <td>[incredibly, think, provoke, article, make, su...</td>\n",
       "      <td>[incredibly, think, provoke, article, make, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2020-10-24 00:59:59</td>\n",
       "      <td>diadexxus  tugrik it was  but that s not sayi...</td>\n",
       "      <td>en</td>\n",
       "      <td>15608869</td>\n",
       "      <td>Ryu_Raccoon</td>\n",
       "      <td>( , diadexxus,  , tugrik, it, was,  , but, tha...</td>\n",
       "      <td>diadexxus   tugrik it be   but that s not sa...</td>\n",
       "      <td>[diadexxus, tugrik, it, be, but, that, s, not,...</td>\n",
       "      <td>[diadexxus, tugrik, say, much, hard, get, bad,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2020-10-24 00:59:59</td>\n",
       "      <td>don lemon meltdown over black trump support   ...</td>\n",
       "      <td>en</td>\n",
       "      <td>1216233063115395072</td>\n",
       "      <td>MackmanAce</td>\n",
       "      <td>(don, lemon, meltdown, over, black, trump, sup...</td>\n",
       "      <td>don lemon meltdown over black trump support   ...</td>\n",
       "      <td>[don, lemon, meltdown, over, black, trump, sup...</td>\n",
       "      <td>[lemon, meltdown, black, trump, support, via, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                 date  \\\n",
       "0    0.0  2020-10-24 00:59:59   \n",
       "1    1.0  2020-10-24 00:59:59   \n",
       "2    2.0  2020-10-24 00:59:59   \n",
       "3    3.0  2020-10-24 00:59:59   \n",
       "4    4.0  2020-10-24 00:59:59   \n",
       "\n",
       "                                               tweet language  \\\n",
       "0   chikooslim i was thinking that since it was t...       en   \n",
       "1  he s been saying that for four years   alllies...       en   \n",
       "2  incredibly thought provoking article  make sur...       en   \n",
       "3   diadexxus  tugrik it was  but that s not sayi...       en   \n",
       "4  don lemon meltdown over black trump support   ...       en   \n",
       "\n",
       "           user_id_str         username  \\\n",
       "0             18491914         slattfri   \n",
       "1             46384399  francesmiddlet2   \n",
       "2           2902130034         mfly1971   \n",
       "3             15608869      Ryu_Raccoon   \n",
       "4  1216233063115395072       MackmanAce   \n",
       "\n",
       "                                                docs  \\\n",
       "0  ( , chikooslim, i, was, thinking, that, since,...   \n",
       "1  (he, s, been, saying, that, for, four, years, ...   \n",
       "2  (incredibly, thought, provoking, article,  , m...   \n",
       "3  ( , diadexxus,  , tugrik, it, was,  , but, tha...   \n",
       "4  (don, lemon, meltdown, over, black, trump, sup...   \n",
       "\n",
       "                                       lemmatization  \\\n",
       "0    chikooslim I be think that since it be the d...   \n",
       "1  he s be say that for four year    alllie   tru...   \n",
       "2  incredibly think provoke article   make sure y...   \n",
       "3    diadexxus   tugrik it be   but that s not sa...   \n",
       "4  don lemon meltdown over black trump support   ...   \n",
       "\n",
       "                                             s_token  \\\n",
       "0  [chikooslim, I, be, think, that, since, it, be...   \n",
       "1  [he, s, be, say, that, for, four, year, alllie...   \n",
       "2  [incredibly, think, provoke, article, make, su...   \n",
       "3  [diadexxus, tugrik, it, be, but, that, s, not,...   \n",
       "4  [don, lemon, meltdown, over, black, trump, sup...   \n",
       "\n",
       "                                               token  \n",
       "0  [chikooslim, I, think, since, daughter, refuse...  \n",
       "1  [say, four, year, alllie, trumplie, time, narc...  \n",
       "2  [incredibly, think, provoke, article, make, su...  \n",
       "3  [diadexxus, tugrik, say, much, hard, get, bad,...  \n",
       "4  [lemon, meltdown, black, trump, support, via, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'all_tweets' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
