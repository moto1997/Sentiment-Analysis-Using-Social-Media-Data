{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.stem import \tWordNetLemmatizer\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1024 = pd.read_csv('Trump/1024t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_1025 = pd.read_csv('Trump/1025t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1026 = pd.read_csv('Trump/1026t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1027 = pd.read_csv('Trump/1027t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1028 = pd.read_csv('Trump/1028t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1029 = pd.read_csv('Trump/1029t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1030 = pd.read_csv('Trump/1030t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1031 = pd.read_csv('Trump/1031t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1101 = pd.read_csv('Trump/1101t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1102 = pd.read_csv('Trump/1102t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1103 = pd.read_csv('Trump/1103t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1104 = pd.read_csv('Trump/1104t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1105 = pd.read_csv('Trump/1105t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1106 = pd.read_csv('Trump/1106t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1107 = pd.read_csv('Trump/1107t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1108 = pd.read_csv('Trump/1108t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1109 = pd.read_csv('Trump/1109t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1110 = pd.read_csv('Trump/1110t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1111 = pd.read_csv('Trump/1111t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1112 = pd.read_csv('Trump/1112t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_1113 = pd.read_csv('Trump/1113t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])\n",
    "t_0106 =  pd.read_csv('Trump/0106t.csv', usecols=['date', 'tweet', 'username','user_id_str','language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets = pd.concat([t_1024, t_1025, t_1026,t_1027,t_1028,t_1029,t_1030,t_1031,t_1101,t_1102,t_1103,t_1104,t_1105,t_1106,t_1107,t_1108,t_1109, t_1110,t_1111,t_1112, t_1113,t_0106], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22848"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trump_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20366"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#screen out\n",
    "trump_tweets = trump_tweets[trump_tweets['language']=='en']\n",
    "trump_tweets.reset_index(inplace = True)\n",
    "len(trump_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove URL from tweets\n",
    "def remove_URL(sample):\n",
    "    \"\"\"Remove URLs from a sample string\"\"\"\n",
    "    return re.sub(r'http\\S+', '', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets['tweet'] = trump_tweets['tweet'].map(lambda x: remove_URL(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Presidential Election 2020 Polls | Trump is Racist | Virus Spreading |  ...   via @YouTube'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets['tweet'][45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to lowercases\n",
    "trump_tweets['tweet'] = trump_tweets['tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all non-alphabetical character with whitespaces\n",
    "trump_tweets['tweet'] = trump_tweets['tweet'].str.replace(r'[^a-zA-Z]',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable = ['parser','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize\n",
    "trump_tweets['docs'] = trump_tweets['tweet'].map(lambda y: nlp(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets['lemmatization'] = trump_tweets['docs'].map(lambda z: \" \".join([word.lemma_ for word in z ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  gopchairwoman   gop trump administration s incompetent response to the coronavirus pandemic have lead to between          and          death that could have be prevent   trump s stupidity be kill we   '"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets['lemmatization'][412]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize\n",
    "trump_tweets['s_token'] = trump_tweets['lemmatization'].map(lambda a:word_tokenize(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['presidential',\n",
       " 'election',\n",
       " 'poll',\n",
       " 'trump',\n",
       " 'be',\n",
       " 'racist',\n",
       " 'virus',\n",
       " 'spread',\n",
       " 'via',\n",
       " 'youtube']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump_tweets['s_token'][45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_tweets.to_csv('trump_cleaned_v2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'trump_tweets' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store trump_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
